# Introduction

Most of our waking hours are now spent staring at backlit rectangles of varying sizes. While the use of of computational devices has become ubiquitous in our daily life, flat and rectangular screens are still the de-facto output channel for consuming and interacting with digital content. While they serve a great purpose at delivering digital content to their viewer, they fail to seamlessly merge with the environment in which they exist. Instead, the user is required to divert his attention from the real-world before him to focus temporarily or for an extended period of time on this flat rectangle, consume the information or complete a task and then come back to the real-world context.

There are multiple problems with this way of handling the meshing of our digital and real lives. For one, our digital lives exists in a completely isolated state. We carry them around in our pockets, but our attention has always to be either on the digital world or the real one. Additionally, the interaction with the different screens that populate our lives are still very limited. While the advances of touch screen technologies have enabled us to use our fingers to interact with the digital content displayed on screen, we can hardly make the case that it leverages the multiple dimensions of the touch sense: textures and pressure are completely omitted. In his seminal talk, "A Humane Representation of Thoughts" [REF], Bret Victor makes a convincing case for designing interfaces that leverages the vast amount of human senses and ways of thinking. He argues that technology right now confines us in thinking only using ways that a computer can easily understand while we have evolved to think with a multitude of different senses that involves our whole body. In order to create a humane media, focusing on the real world itself seems a promising idea: if we have evolved to think withing a real, physical world, leveraging these millions of years of evolution should not only be logical but a sustainable option as well. Indeed, instead of letting our bodies sit at a desk all day to atrophy, while our head and fingers do all the work, we should put them to use to instead help us think new ideas.

This idea of anchoring digital interaction in the real world is by no mean novel. The field of Tangible User Interface (TUI) is especially interested in giving form to digital matter. The first concept of TUI was a marble answering machine [REF] where marbles embodied messages received while the recipient was away from home. Professor Iroshi Ishii has been promoting this vision for more than two decades now. Starting with the proposal of Graspable Interfaces [REF: Brick-1995]the Tangible Bits [REF] vision where physical handles on the digital information was offered, it has now evolved to the concept of what Ishii calls Radical Atoms [REF] which hypothesize a physical material which properties can be digitally controlled.

<!-- example of "what is a phone" by bill boxton in designing user interfaces. Gets into a car, throw his phone on the passenger seat, phone connect via bluetooth to radio, continue conversation, drive the car, arrive at destination an pick up the phone to continue conversation while walking. In this example, what is a "phone", is it the mobile phone, the car? What is important is the *conversation*. In the same idea, what is a screen? -->

<!-- Example with the ultimate display (Sutherland 1965). Not only a display but a room where you walk in, move around. It involves the whole body (see reference for this) -->