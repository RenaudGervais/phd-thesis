#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass classicthesis
\use_default_options true
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding default
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Spatial Augmented Reality as a Mixing Medium
\begin_inset CommandInset label
LatexCommand label
name "cha:sar"

\end_inset


\end_layout

\begin_layout Standard
This chapter provides an overview of Augmented Reality (AR) and, more specifical
ly, Spatial Augmented Reality (SAR).
 Since the work presented in all following chapters uses SAR, this chapter
 aims at pooling the related work and implementation details in a single
 place in order to avoid useless repetitions.
 The goal is also to explain enough background to provide a global understanding
 of SAR principles and some details on the implementation used throughout
 the thesis.
 While we will cover some basic notions of SAR, an interested reader can
 get a more thorough understanding of the different principles of this AR
 paradigm in Bimber and Raskar's book on the topic 
\begin_inset CommandInset citation
LatexCommand citep
key "Bimber2005"

\end_inset

.
 
\end_layout

\begin_layout Section
Background
\end_layout

\begin_layout Standard
This section covers the main concepts and definitions related to AR and
 SAR.
 AR is first defined and a brief overview of its history is given.
 Then we will focus on one of its subset: SAR.
\end_layout

\begin_layout Subsection
Augmented Reality
\end_layout

\begin_layout Standard
As mentioned in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "cha:introduction"

\end_inset

, augmented reality consists in overlaying computer generated information
 on a real-world experience.
 The overarching goal of AR is to create a seamless experience, merging
 both real and digital information.
 Sutherland 
\begin_inset CommandInset citation
LatexCommand citep
key "Sutherland1965"

\end_inset

, as soon as 1965, proposed the idea of an 
\begin_inset Quotes eld
\end_inset

Ultimate Display
\begin_inset Quotes erd
\end_inset

: a room within which the computer could control the existence of matter.
 A few years later, he was also the first to build an AR system, taking
 the form of a head-mounted display (HMD) 
\begin_inset CommandInset citation
LatexCommand citep
key "Sutherland1968"

\end_inset

.
 However, using a HMD is only one way to visually augment the real world.
 Azuma later provided a definition of AR that is flexible enough so not
 to be technology dependent 
\begin_inset CommandInset citation
LatexCommand citep
key "Azuma1997"

\end_inset

.
 An AR system would then have the following properties:
\end_layout

\begin_layout Enumerate
Combines real and virtual
\end_layout

\begin_layout Enumerate
Is interactive in real-time
\end_layout

\begin_layout Enumerate
Is registered in three dimensions
\end_layout

\begin_layout Standard
AR is neither purely a real-world experience nor is it pure virtual reality.
 Milgram and Kishino 
\begin_inset CommandInset citation
LatexCommand citep
key "Milgram1994"

\end_inset

 proposed a taxonomy for mixed reality display technologies taking the form
 of a continuum between reality and virtual reality.
 At the left extremity is unaltered reality.
 On the other side lies virtual reality, which replaces reality completely
 relying on different sensory channels -- usually visual and auditory.
 Augmented reality is located on the left-hand spectrum of mixed reality.
 Indeed, AR is centered on real-world elements onto which digital information
 is added.
 Note that Milgram, in his virtuality continuum, did not explore the different
 display devices for AR.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-mr-continuum.jpg
	lyxscale 50
	width 100line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Milgram's virtuality continuum as described in 
\begin_inset CommandInset citation
LatexCommand Citep
key "Milgram1994"

\end_inset

.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Milgram's virtuality continuum
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This proximity to reality is very well illustrated by the title of the special
 issue of the 
\emph on
Communication of ACM
\emph default
 in 1993 -- 
\begin_inset Quotes eld
\end_inset

Computer Augmented Environments: Back to the Real World
\begin_inset Quotes erd
\end_inset

 -- which contributed in establishing the AR research agenda 
\begin_inset CommandInset citation
LatexCommand citep
key "Wellner1993"

\end_inset

.
 In 1998, Mackay 
\begin_inset CommandInset citation
LatexCommand citep
key "Mackay1998"

\end_inset

 reflected back on this issue and described the three basic approaches to
 augmenting real-world objects:
\end_layout

\begin_layout Description
\begin_inset ERT
status open

\begin_layout Plain Layout

Augment the user:
\end_layout

\end_inset

 The user has either to wear or carry a device which is used to see the
 augmented information.
 This usually takes the form of a HMD or a mobile device, using see-through
 or video see-through approaches.
\end_layout

\begin_layout Description
\begin_inset ERT
status open

\begin_layout Plain Layout

Augment the physical object:
\end_layout

\end_inset

 Physically modify the objects themselves with different input/ouput components.
 For example, an object's surface could be covered by a thin film display,
 such as what is described in the Organic User Interfaces vision (see Section
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:intro-oui"

\end_inset

).
 This hardware modification with computational devices is also reminiscent
 of the Internet of Things trend 
\begin_inset CommandInset citation
LatexCommand citep
key "Atzori2010"

\end_inset

.
\end_layout

\begin_layout Description
\begin_inset ERT
status open

\begin_layout Plain Layout

Augment the environment:
\end_layout

\end_inset

 Independent devices are installed in the environment which collect information
 from their surroundings and display information onto objects.
 They also handle the users interaction.
 This approach leaves both the users and the physical objects unaffected.
 This approach is the one leveraged by SAR which will be explored in more
 depth in the rest of this chapter.
\end_layout

\begin_layout Standard
It is important to note that while the vast majority of the AR research
 community focused on augmenting the visual sensory channel, it is not restricte
d to it in any way.
 For example, Dobler et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Dobler2002"

\end_inset

 used AR to enable users to see and place sound sources in space.
 Another example is the imaginary reality game of Baudisch and his colleagues
 
\begin_inset CommandInset citation
LatexCommand citep
key "Baudisch2013"

\end_inset

.
 In this game, two teams played a basketball game with the exception that
 there is no physical ball to manipulate.
 Instead, there is only an imaginary ball that exists solely via a computer
 analyzing the playing area in real-time.
 The location of the ball has to be inferred by the player using sound cues
 given by the system managing the game.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
place picture of baudisch ball game
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Spatial Augmented Reality
\end_layout

\begin_layout Standard
SAR is subset of AR that consists in displaying the augmented content 
\emph on
in
\emph default
 the environment using projectors or displays.
 The first steps in this direction have been highlighted in the 
\begin_inset Quotes eld
\end_inset

Office of the Future
\begin_inset Quotes erd
\end_inset

 vision 
\begin_inset CommandInset citation
LatexCommand citep
key "Raskar1998"

\end_inset

.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-ootf"

\end_inset

 provides a good illustration of the authors' vision.
 It describes ideas and techniques for creating immersive in-situ displays,
 building upon the notions of the CAVE system, in a normal office environment.
 By using computer vision to compute the depth of every pixel of a camera,
 they could correct the projected images according to the topology of the
 projection support.
 Their dream was to have a room in which the light of 
\emph on
every millimeter
\emph default
 could be controlled at 
\emph on
every millisecond
\emph default
.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-ootf-off-raskar.jpg
	lyxscale 20
	width 75line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-ootf-off"

\end_inset

A normal office space where part of the walls and table can be used as spatial
 displays.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-ootf-raskar.png
	lyxscale 20
	width 75line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-ootf-on"

\end_inset

When the displays are active, they can be for example used to create a virtual
 shared office.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-ootf"

\end_inset

Conceptual sketch of the Office of the future, as presented in 
\begin_inset CommandInset citation
LatexCommand citep
key "Raskar1998"

\end_inset

.
 Image courtesy of Raskar et al.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Conceptual sketch of Raskar's et al.
 the Office of the future
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Based on the vision of the Office of the Future, Raskar and his colleagues
 formalized these techniques into a new paradigm to achieve AR, which they
 named 
\emph on
Spatially
\emph default
 AR 
\begin_inset CommandInset citation
LatexCommand citep
key "Raskar1998a"

\end_inset

 -- nowadays, it is more often referred to as 
\emph on
Spatial
\emph default
 AR or SAR.
 They put emphasis on augmenting the 
\emph on
environment
\emph default
 instead of the users' field of view.
 By tracking a user's head position, they proposed a set of techniques to
 project on irregular surfaces in the environment so as to generate perceptual
 illusions for the user.
 When updating the projection in real-time, it is possible to make it appear
 as if virtual objects are registered in 3D to physical objects.
 This process is often used in art to create surreal and surprising illusions
 that only works for a specific viewpoint.
 It is usually referred to as 
\emph on
anamorphic illusions
\emph default
.
 A basic example of the principle is shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-anamorphic-mug"

\end_inset

.
 Other work using SAR to produce anamorphic illusions include 
\begin_inset CommandInset citation
LatexCommand citep
key "Lee2009"

\end_inset

 which used a mobile robot mounted with a projector.
 More recently, Benko et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Benko2014"

\end_inset

 proposed a dyadic SAR system: a room for two users where each person, facing
 each other, have a view on common virtual elements.
 Interestingly, the system also uses the users themselves as projection
 surfaces for the other user's view (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-dyadic-sar"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-anamorphic-mug-photo.jpg
	lyxscale 25
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-anamorphic-mug-flat.jpg
	lyxscale 5
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-anamorphic-mug"

\end_inset

A simple example of anamorphic illusion.
 
\emph on
(a)
\emph default
 When the viewpoint of the camera is exactly at the right spot, the image
 of the augmented mug appears as intended.
 
\emph on
(b)
\emph default
 The actual image printed on the sheet of paper used in order to produce
 the image on the left.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
A simple example of anamorphic illusion
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-dyadic-sar.jpg
	lyxscale 20
	width 100line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-dyadic-sar"

\end_inset

The Mano-a-Mano system using a dyadic projection system to create anamorphic
 illusions in a room for two users.
 Image courtesy of Benko et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Benko2014"

\end_inset

.
 
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Dyadic projection system
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Projection of digital information in the environment has been done before.
 Wellner 
\begin_inset CommandInset citation
LatexCommand citep
key "Wellner1993a"

\end_inset

 presented his DigitalDesk in 1993 which projected digital documents on
 physical paper laid out on a desk and with which it was possible to interact
 with a pen.
 This work was essentially closing the loop of the Desktop metaphor used
 ubiquitously in computing since the 1970s
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citep
key "Johnson1989"

\end_inset

 (not sure this reference is really required here)
\end_layout

\end_inset

, by displaying back the digital desktop on a real desk.
 Mackay 
\begin_inset CommandInset citation
LatexCommand citep
key "Mackay1998"

\end_inset

 also worked with augmented paper using projection for engineering drawings,
 video edition and flight control.
 While not creating augmented objects per se, Underkoffler and Ishii used
 a combination of tangibles and projection in the environment to create
 simulations.
 They presented an optical prototyping tool where various optical elements
 were controlled by physical objects while the a simulation of the light
 behavior was projected on a worktable 
\begin_inset CommandInset citation
LatexCommand citep
key "Underkoffler1998"

\end_inset

.
 In 
\emph on
Urp
\emph default
 
\begin_inset CommandInset citation
LatexCommand citep
key "Underkoffler1999"

\end_inset

, they re-used the same underlying technology -- which they named 
\emph on
I/O Bulb
\emph default
 for its capacity to use light as input and output -- to create a urban
 planning tool which projected simulated shadows of physical wooden structures
 laid out on a table.
 Other types of simulations, such as fluid flow, was possible.
\end_layout

\begin_layout Standard
SAR can also be used to change the appearance of objects by mapping different
 textures to its surface (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-shader-lamps"

\end_inset

).
 This idea was introduced under the term 
\begin_inset Quotes eld
\end_inset

Shader Lamps
\begin_inset Quotes erd
\end_inset

 by Raskar and his colleagues in 2001 
\begin_inset CommandInset citation
LatexCommand citep
key "Raskar2001a"

\end_inset

.
 The term 
\begin_inset Quotes eld
\end_inset

shader
\begin_inset Quotes erd
\end_inset

 was used to highlight the fact that this technique could be used to create
 the illusion of different materials and simulate artificial illuminations
 on the augmented objects.
 One of the advantage of this technique over anamorphic illusion is that
 it does not require the users' head position
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Note that simulating artificial lighting still requires the head position
 of the viewer.
\end_layout

\end_inset

.
 Therefore, it allows multiple users to see the same augmentation simultaneously.
 Bandyopadhyay et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Bandyopadhyay2001"

\end_inset

 made those shader lamps dynamic, using them in conjunction with a tracked
 pen to allow users to digitally paint a tracked physical object.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-shader-lamps-off.jpg
	lyxscale 20
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-shader-lamps-on.jpg
	lyxscale 20
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-shader-lamps"

\end_inset

Using a projected light to change the appearance of a physical object.
 Image courtesy of Raskar et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Raskar2001a"

\end_inset

.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Shader lamps
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
How does it work?
\begin_inset CommandInset label
LatexCommand label
name "sec:sar-how-does-it-work"

\end_inset


\end_layout

\begin_layout Standard
In this section, we are taking a closer look at how SAR is actually achieved.
 While most of the concepts presented here can be generalized from a standard
 AR pipeline, we will focus on its spatial specialization.
 As discussed in the previous section, there are mainly two different types
 of augmentation that can be done with SAR: texture mapping -- Shader Lamps
 -- and anamorphic illusions.
 The creation of augmented objects rely more heavily on texture mapping.
 It is the main technique used in Chapters 
\begin_inset CommandInset ref
LatexCommand ref
reference "cha:cursar"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "cha:tangible-viewports"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "cha:teegi"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "cha:tobe"

\end_inset

.
 However, since Chapters 
\begin_inset CommandInset ref
LatexCommand ref
reference "cha:cursar"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "cha:tangible-viewports"

\end_inset

 also rely slightly on anamorphic illusions, they will also be briefly covered
 in this section.
\end_layout

\begin_layout Subsection
Texture Mapping
\begin_inset CommandInset label
LatexCommand label
name "sub:sar-texture-mapping"

\end_inset


\end_layout

\begin_layout Standard
In order to create an augmented scene, a virtual counterpart of every real-world
 component that is used to create the augmented experience is required.
 Indeed, we want to create the illusion that augmented graphics displayed
 on the object's surface are actually 
\emph on
part of
\emph default
 the object.
 This first require a virtual version of the object to be augmented.
 All the digital operations and animations will be created and handled in
 the virtual world using this virtual object.
 Then, we model the projection cone of our projectors in the real-world.
 This consists in knowing the behaviors of the pixels in space.
 A virtual camera is then created based on the projector's parameters.
 We finally reproject this virtual camera view on the real world environment
 using the projector.
\end_layout

\begin_layout Standard
This pipeline and its virtual counterpart are respectively summarized in
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-pipeline"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-pipeline-virtual"

\end_inset

.
 It can be broken down in four main components -- labeled from 1 to 4 in
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-pipeline"

\end_inset

 -- which will be described in further details in the following subsections:
\end_layout

\begin_layout Enumerate
Augmented object geometry.
\end_layout

\begin_layout Enumerate
Position of the augmented object in the world: tracking.
\end_layout

\begin_layout Enumerate
Position of the projector(s) in the world: extrinsic calibration.
\end_layout

\begin_layout Enumerate
How the pixels of the projector are traveling through physical space: intrinsic
 calibration.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-pipeline.png
	lyxscale 30
	width 100line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-pipeline"

\end_inset

A summary of a SAR pipeline.
 
\begin_inset Formula $W$
\end_inset

 represents the world's coordinate system's origin.
 
\emph on
(1)
\emph default
 The exact geometry of the augmented object must be known, either by using
 3D scanning of an existing object or by creating a 3D model and building
 it using, for example, 3D printing.
 
\emph on
(2)
\emph default
 The position and orientation of the object in world space (
\begin_inset Formula $M_{W\rightarrow Obj}$
\end_inset

) must be known via a tracking solution or manual measurements.
 
\emph on
(3)
\emph default
 The position and orientation of the projector in world space (
\begin_inset Formula $M_{W\rightarrow Proj}$
\end_inset

) must also be known.
 
\emph on
(4)
\emph default
 The intrinsic parameters of the projector (
\begin_inset Formula $M_{Proj}$
\end_inset

) is required to know how the pixels are being distributed in the real-world
 environment.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
A summary of a SAR pipeline
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-pipeline-virtual.png
	lyxscale 30
	width 100line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-pipeline-virtual"

\end_inset

The virtual counterpart of the SAR pipeline shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-pipeline"

\end_inset

.
 The 3D model of the real object is moved to the right location in virtual
 space 
\begin_inset Formula $M_{W\rightarrow Obj}$
\end_inset

 as fed by the tracking solution.
 Then a virtual camera is created using the parameters returned from the
 extrinsic (
\begin_inset Formula $M_{W\rightarrow Proj}$
\end_inset

) and intrinsic (
\begin_inset Formula $M_{Proj}$
\end_inset

) calibration of the projector.
 Finally, the image produced by the virtual camera is sent to the projector
 to create the augmented scene.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
The virtual counterpart of the SAR pipeline
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Geometry of the Object
\end_layout

\begin_layout Standard
The first step in order to create an augmented object is to have a 3D model
 corresponding to the physical object to be augmented.
 It is possible to approach the problem from two different angles:
\end_layout

\begin_layout Itemize
From real to virtual
\end_layout

\begin_layout Itemize
From virtual to real
\end_layout

\begin_layout Paragraph
From real to virtual
\end_layout

\begin_layout Standard
This approach consists in starting from a real object and then creating
 a virtual version of it.
 One of the most straightforward way to achieve this is by simply measuring
 -- using of example a measuring tape and a protractor -- different key
 points of the object.
 They are then processed in a 3D Computer Assisted Design (CAD) software
 to form a more or less complete geometric shape.
 This method works fine if the measurements are made carefully and if the
 object is relatively simple.
 However, as the geometry of the object increases, this method becomes painstaki
ngly slow and error prone.
\end_layout

\begin_layout Standard
An alternative way to achieve this is to rely on an automatic process that
 will generate the 3D points for us by scanning the object in 3D.
 Scanning can be done in many different ways including cameras and lasers
 -- such as LiDAR systems.
 Recent advances in computer vision techniques and the democratization of
 depth cameras such as the Microsoft Kinect
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
texttrademark{}
\end_layout

\end_inset

 has enabled 3D scanning at very low costs 
\begin_inset CommandInset citation
LatexCommand citep
key "Newcombe2011"

\end_inset

.
 However, the Kinect's sensors are still relatively low resolution and do
 not operate well below a certain distance -- 0.5 meters for the Kinect v2.
 Consequently, relatively small objects do not produce high fidelity 3D
 models.
 While it might be sufficient for certain types of augmentation, anything
 related to design and precision applications will suffer greatly from a
 lack of precision in the 3D model.
 Scanning can also be achieved using structured light patterns captured
 by a camera 
\begin_inset CommandInset citation
LatexCommand citep
key "Moreno2012"

\end_inset

.
 This method will produce a 3D point cloud which will then need to be meshed.
\end_layout

\begin_layout Paragraph
From virtual to real
\end_layout

\begin_layout Standard
This method is typical of industrial settings where object fabrication starts
 with a digital design.
 The object is then physically built either manually -- for example with
 clay during the design stages -- or with machines such as CNC mills.
 However, recent advances in digital fabrication technologies, such as 3D
 printing and laser cutting, has widened considerably the accessibility
 object making.
 One of the main advantage of digital fabrication is that it ensures that
 the physical object corresponds 
\emph on
exactly
\emph default
 to the 3D model (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-3d-printing-polyclock"

\end_inset

).
 Moreover, 3D printing also has the benefit of providing some control over
 the material that is used for the object creation.
 Indeed, in SAR settings, the properties of the material receiving the projector
's light is crucial.
 That is, a diffuse white material is often best.
 Moreover, advances in 3D printing technologies allow for more fine grained
 control over the material being used at very specific locations in the
 object.
 More recently, it has even been used as a way to create interactive components
 by printing embedded optical components 
\begin_inset CommandInset citation
LatexCommand citep
key "Willis2012"

\end_inset

 and curved displays 
\begin_inset CommandInset citation
LatexCommand citep
key "Brockmeyer2013"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-polyclock-wireframe.png
	lyxscale 10
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-3dprinting-clock.jpg
	lyxscale 30
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-3d-printing-polyclock"

\end_inset

3D printing allows to create an exact replica of a digital model.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
3D printing
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Tracking
\end_layout

\begin_layout Standard
Tracking is the process by which the position and orientation -- which we
 will call 
\emph on
pose
\emph default
 from now on -- of the physical object to be augmented is retrieved in world
 space.
 This corresponds to step 2 in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-pipeline"

\end_inset

.
 Once the exact geometry of the object is known, we must replicate its real
 world pose in the virtual environment.
 The requirements in precision and performance depend of the application
 at hand.
\end_layout

\begin_layout Standard
The precision
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Note that when talking about precision, we mean it in a way that encompasses
 both 
\emph on
precision
\emph default
 and 
\emph on
accuracy
\emph default
.
 The difference between these two concepts are highlighted in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:0a-precision-and-accuracy"

\end_inset

.
\end_layout

\end_inset

 is typically expressed in meters and degrees although it is often found
 expressed in pixels when the tracking solution relies on computer vision.
 Having a precise tracking system -- and a good projector calibration (see
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:sar-projector-calibration"

\end_inset

) -- is important to minimize augmentation artifacts such as bleeding or
 misregistrations between the augmented content and the physical object
 (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-projection-artifacts"

\end_inset

).
 Performance is is often evaluated in milliseconds and is indicative of
 the system's capacity to sustain real-time updates.
 That is, when the physical object is moved, how much latency is created
 by the system having to compute the new pose of the object.
 Naturally, high tracking performance is required whenever the physical
 object is to be manipulated and moved around a lot.
 On the opposite, some setups require very little manipulation and can even
 fare well without any dynamic tracking solution, for example if the object
 never needs to be manipulated physically
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The study reported in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "cha:cursar"

\end_inset

 did not require any tracking.
\end_layout

\end_inset

.
 Tracking is one the most challenging aspect of the AR pipeline and has
 been the main focus of the ISMAR community for a long time 
\begin_inset CommandInset citation
LatexCommand citep
key "Duh2008"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-bleeding.jpg
	lyxscale 10
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Bleeding
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-misregistration.jpg
	lyxscale 10
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Misregistration
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-projection-artifacts"

\end_inset

Typical artifacts encountered in SAR.
 
\emph on
(a) 
\emph default
Bleeding of some of the projected pixels outside of the object's surfaces.
 Here, bleeding can be seen as a white silhouette on the table.
 
\emph on
(b)
\emph default
 Misregistration artifacts where part of the objects are clearly misaligned.
 The projection on the feet of the clock are offset from their intended
 position.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Typical artifacts encountered in SAR
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
There are multiple ways to tackle the tracking problem in a variety of contexts:
 magnetic sensors, microelectromechanical systems
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
MEMS
\end_layout

\end_inset

, global navigation satellite systems
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
GNSS.
 GPS is an instance of a GNSS.
\end_layout

\end_inset

, sonar and computer vision, to name only a few.
 It is however not our goal to go in depth on this topic since it is not
 the main interest of this dissertation.
 We will discuss some of the techniques relying on computer vision since
 they are the most commonly found for small object tracking in an AR context.
 The main tracking technology used in the different projects highlighted
 in this thesis is based on computer vision.
\end_layout

\begin_layout Standard
It is important to note that the choice of using SAR imposes certain constraints
 on the chosen tracking solution.
 This is because the object being tracked is also the 
\emph on
display
\emph default
.
 Therefore, any components attached to the object for tracking purposes
 should avoid occluding the surface onto which the augmentation will be
 displayed.
 Moreover, since we are projecting dynamic content onto the object, any
 method relying on a static object texture should be avoided.
\end_layout

\begin_layout Paragraph
Fiducial Markers
\begin_inset CommandInset label
LatexCommand label
name "par:sar-fiducial-markers"

\end_inset


\end_layout

\begin_layout Standard
The use of markers detected by a camera has become the 
\begin_inset Quotes eld
\end_inset

visual trademark
\begin_inset Quotes erd
\end_inset

 of AR.
 They are comprised of patterns that are easy to detect and identify for
 computer vision algorithms.
 Moreover, their easily distinguishable square shape is used to compute
 their pose in 6 degrees of freedom (DoF) -- position and rotation -- in
 the camera's coordinate system.
 Enabling libraries in this area are ARToolkit 
\begin_inset CommandInset citation
LatexCommand citep
key "Kato1999"

\end_inset

 and ARToolkitPlus 
\begin_inset CommandInset citation
LatexCommand citep
key "Wagner2007"

\end_inset

.
 An example of marker for each of these library is shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-artoolkit-markers"

\end_inset

.
 Other libraries -- e.g.
 reacTIVision 
\begin_inset CommandInset citation
LatexCommand citep
key "Kaltenbrunner2007"

\end_inset

 and BullsEyes 
\begin_inset CommandInset citation
LatexCommand citep
key "Klokmose2014"

\end_inset

 -- are more specifically designed for tabletop use and are limited to 3
 DoF 
\begin_inset Formula $(x,y,θ)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-artoolkit-marker.png
	lyxscale 50
	width 35line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
ARToolkit marker 
\begin_inset CommandInset citation
LatexCommand citep
key "Kato1999"

\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-artoolkitplus-marker.png
	lyxscale 50
	width 35line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
ARToolkitPlus marker 
\begin_inset CommandInset citation
LatexCommand citep
key "Wagner2007"

\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-artoolkit-markers"

\end_inset

Example of fiducial markers commonly used.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Fiducial markers used for tracking
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Using fiducial markers require having a calibrated camera
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Camera calibration is a process very similar, yet simpler, to projector
 calibration (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:sar-projector-calibration"

\end_inset

).
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Interested readers can also refer to Section 
\begin_inset Note Note
status open

\begin_layout Plain Layout
@TODO: decide if we do an appendix section for camera calibration
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

.
 This process essentially consists of transforming pixel measurements in
 real-world coordinate system -- i.e.
 meters.
 This tracking solution has the obvious advantages of being cheap, accessible
 and can achieve good and robust precision.
 The markers are required to be planar, therefore it is important that they
 are not folded or distorted in any way.
 They also require to be fully visible in the camera's frustrum in order
 to be detected.
 To overcome this limitation, it is possible to combine multiple markers
 together that acts like a single tracked body.
 Their form factor make them difficult to affix on complex 3D objects.
 Another drawback is their visual clutter.
 Indeed, their appearance and form factor can be disturbing for users when
 manipulating a physical object.
 Some research projects have successfully reduced the markers' visibility
 to the naked eye by relying on the infrared spectrum 
\begin_inset CommandInset citation
LatexCommand citep
key "Maas2012,Willis2013"

\end_inset

.
\end_layout

\begin_layout Paragraph
Natural Feature Tracking
\end_layout

\begin_layout Standard
Tracking natural features is based on image features -- characteristic points
 that are processed in certain ways which are easier to match for computer
 vision algorithms -- extraction and matching.
 Commonly used are SIFT 
\begin_inset CommandInset citation
LatexCommand citep
key "Lowe1999"

\end_inset

, SURF 
\begin_inset CommandInset citation
LatexCommand citep
key "Bay2006"

\end_inset

 or ORB 
\begin_inset CommandInset citation
LatexCommand citep
key "Rublee2011"

\end_inset

.
 Natural feature tracking can be used in a variety of ways.
 For instance, it can be used following the same principles of fiducial
 marker based pose estimation presented in the previous section.
 It mainly consists in replacing the very obvious markers, such as the ones
 in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-artoolkit-markers"

\end_inset

, by more natural images such as a logo, a photograph or the natural texture
 of an object.
 Professional solutions, such as the Vuforia
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textsuperscript{
\backslash
textregistered}
\end_layout

\end_inset

 framework
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

http://www.qualcomm.com/products/vuforia
\end_layout

\end_inset


\end_layout

\end_inset

, propose AR solution based on this technology.
 Alternatively, natural feature tracking is often used in scenarios where
 you have to track the camera pose where the camera is evolving in an environmen
t to be augmented using video see-through techniques.
 Approaches such as Simultaneous Localization and Mapping (SLAM) 
\begin_inset CommandInset citation
LatexCommand citep
key "Leonard1991"

\end_inset

 can leverage the use of these images features, even when using a single
 camera 
\begin_inset CommandInset citation
LatexCommand citep
key "Davison2007"

\end_inset

.
\end_layout

\begin_layout Standard
This approach is difficult to use in SAR contexts for obvious reasons: by
 augmenting the object using projected light, we alter its appearance.
 Hence, it disturbs the tracking since it is based on the object's texture
 in order to provide stable pose estimation.
\end_layout

\begin_layout Paragraph
Depth-Based Tracking
\end_layout

\begin_layout Standard
This category is relatively broad as it encompasses a lot of different technique
s.
 We will only discuss the ones that has been considered for our work with
 SAR.
 It consists in using 3D -- or 2.5D -- data to track an object in space.
 As mentioned above, the democratization of depth sensors such as the Microsoft
 Kinect
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
texttrademark{}
\end_layout

\end_inset

 or the Asus Xtion
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
texttrademark{}
\end_layout

\end_inset

, has made depth sensing a realistic approach with off-the-shelf components.
 Generating depth information 2D sensors such as cameras can also be achieved
 by using multiple sensors together.
 First, stereo pairs -- two devices that have partially the same view on
 an environment and that are calibrated together -- need to be created.
 Stereo calibration is done in order to determine the relative positions
 of the two cameras' frustums.
 Then, any matching point located in each camera's field of view can be
 triangulated to determine its depth.
\end_layout

\begin_layout Standard
One approach to track object from depth cameras is to compare the 3D model
 of the object to the point cloud generated by the camera(s).
 For example, by generating a template point cloud from the 3D model of
 the object, it could be possible to use point cloud registration techniques,
 such as the Iterative Closest Point algorithm 
\begin_inset CommandInset citation
LatexCommand citep
key "Besl1992"

\end_inset

, to register it to the point cloud generated from the camera.
 While these methods can work in real-time in some cases, they are computational
ly expensive and the tracking precision is highly dependent on the quality
 of the camera's sensor.
 However, higher resolution camera obviously require more processing power.
\end_layout

\begin_layout Standard
Another approach in this category is the use of motion capture systems.
 These includes professional solutions used in movie studios such as OptiTrack
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textsuperscript{
\backslash
textregistered}
\end_layout

\end_inset


\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://www.optitrack.com/
\end_layout

\end_inset


\end_layout

\end_inset

 or Vicon
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textsuperscript{
\backslash
textregistered}
\end_layout

\end_inset


\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://www.vicon.com/
\end_layout

\end_inset


\end_layout

\end_inset

 systems.
 They work on the same basic principles as the depth sensing cameras --
 using multiple infrared (IR) cameras to create a tracking volume -- but
 are highly optimized for speed and stability.
 By tracking only small reflective markers affixed to the physical object,
 which are illuminated with IR light, these systems can reach refresh rates
 of 120 frames per second and millimetric precisions.
 By comparison, most displays refresh between 50-75 per second since most
 persons have a perceptual time resolution of 50-Hz 
\begin_inset CommandInset citation
LatexCommand citep
key "Ware2012"

\end_inset

.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-reflective-markers"

\end_inset

 shows an example of an object tracked using multiple reflective balls attached
 to its base.
 The markers are tracked as a group and therefore tracking is robust to
 partial occlusions when enough markers and/or cameras are used.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-reflective-markers.jpg
	lyxscale 20
	width 35line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-reflective-markers"

\end_inset

Multiple reflective balls are attached to an object's base.
 IR light is shed on them and tracked by multiple IR cameras.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Motion tracking system markers
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Projector Calibration
\begin_inset CommandInset label
LatexCommand label
name "sub:sar-projector-calibration"

\end_inset


\end_layout

\begin_layout Standard
Calibration is the process of characterizing the behavior of the light in
 relation to the optical device we are using.
 Essentially, a projector can be seen as an inverse camera: it emits light
 instead of capturing it.
 Nonetheless, the optical components are more or less the same.
 However, calibrating a projector is slightly more difficult than calibrating
 a camera since it has no mean to 
\begin_inset Quotes eld
\end_inset

see
\begin_inset Quotes erd
\end_inset

 the real world.
 In an AR context, our overarching goal is to be able to determine exactly
 what the projector is 
\begin_inset Quotes eld
\end_inset

seeing
\begin_inset Quotes erd
\end_inset

 so that we can create a corresponding virtual camera to correctly display
 the augmented content.
 We will therefore have to tackle the problem in an indirect way compared
 to a camera calibration process.
\end_layout

\begin_layout Standard
A projector or camera can typically be characterized by two components:
 
\emph on
extrinsic
\emph default
 parameters and 
\emph on
intrinsic
\emph default
 parameters.
 They respectively refer to steps 3 and 4 of Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-pipeline"

\end_inset

.
 A simplified explanation of these parameters are described below.
 An interested reader can refer to Appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:0a-pinhole-camera-model"

\end_inset

 for more details on the pinhole camera model used here.
\end_layout

\begin_layout Paragraph
Extrinsics
\end_layout

\begin_layout Standard
The extrinsic parameters of a projector simply refer to the position and
 orientation of the imaging component, in the chosen world coordinate system.
 This can be modeled as a matrix allowing to convert a point's position,
 expressed in world coordinates, in the projector's local coordinate system.
\end_layout

\begin_layout Paragraph
Intrinsics
\end_layout

\begin_layout Standard
The intrinsic parameters refer to the projection cone of the optical system
 as well as the modeling of deformation in the image caused by the imperfection
 of the optics.
 This can be modeled as a matrix enabling to convert the position of a point,
 expressed in the projector's coordinate system in meters, in a position
 on the imaging plane expressed in pixels.
\end_layout

\begin_layout Paragraph
Calibration
\begin_inset CommandInset label
LatexCommand label
name "par:sar-calibration"

\end_inset


\end_layout

\begin_layout Standard
The calibration process can be conducted in a number of ways.
 The majority of them are based or inspired by Zhang's method 
\begin_inset CommandInset citation
LatexCommand citep
key "Zhang2000"

\end_inset

.
 It estimates both the intrinsic and extrinsic parameters using a set of
 correspondences between 2D points located on the imaging sensor of the
 projector or camera with their positions in world space.
 Obviously, we could consider selecting points in the imaging plane and
 manually measure their location in world space.
 However, manual measurements are very tedious and error prone.
 Alternatively, we can consider a semi-automatic method to help us generate
 these correspondences more quickly.
\end_layout

\begin_layout Standard
In the case of a camera, you can use a predefined pattern which contains
 points of physically known positions that is also easily detectable using
 computer vision.
 A black and white chessboard is usually a good choice.
 Therefore, since we can automatically detect the chessboard corners in
 the image -- as seen in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-chessboard-detection"

\end_inset

 --, correspondences between image plane positions and real-world positions
 can be generated quickly by simply moving the chessboard to different locations.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-chessboard-detection.jpg
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-chessboard-detection"

\end_inset

A chessboard typically used in camera calibration.
 The physical size of the squares are known and can be automatically detected
 using computer vision.
\begin_inset Argument 1
status open

\begin_layout Plain Layout
A chessboard typically used in camera calibration
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Calibrating a projector is similar.
 However, since the projector cannot 
\begin_inset Quotes eld
\end_inset

see
\begin_inset Quotes erd
\end_inset

, the problem has to be tackled in a slightly different way.
 First, a standard camera is calibrated so that it is possible to convert
 pixel positions in real-world distances.
 Then, instead of using a printed chessboard, we project one on a planar
 surface using the projector.
 Since we are projecting the chessboard ourselves, we already 
\emph on
know
\emph default
 the corners' positions on the image plane.
 Since the chessboard corners can be detected automatically by the camera
 and that their pose can be determined using the camera calibration, corresponde
nces between the image plane of the projector and the real world coordinate
 system can be generated.
 Different tools and methods exists to calibrate a camera-projector pair
 together -- for example, see 
\begin_inset CommandInset citation
LatexCommand citep
key "Audet2009,Moreno2012"

\end_inset

.
\end_layout

\begin_layout Subsection
Anamorphic Illusions
\begin_inset CommandInset label
LatexCommand label
name "sub:sar-anamorphic-illusions"

\end_inset


\end_layout

\begin_layout Standard
The process to generate anamorphic illusions is slightly different than
 texture mapping.
 However, it requires the same basic components: knowledge of the physical
 world's geometry, in real time, and the location of pixels in space --
 i.e.
 calibration.
 In addition, we also need to know the user's viewpoint.
 Texture mapping consists in projecting 
\emph on
flat
\emph default
 textures on the surface of real world objects.
 Therefore, the object will appear correctly augmented from any viewpoint.
 If we are interested in the creation of 
\emph on
3D illusions
\emph default
, this is where we have to rely on anamorphosis.
 The process is very similar to the creation of a fishtank VR 
\begin_inset CommandInset citation
LatexCommand citep
key "Ware1993"

\end_inset

 experience, except that SAR gives more flexibility -- the whole environment
 can act as the display.
\end_layout

\begin_layout Standard
To illustrate the process of creating such 3D illusions, we will take the
 example of a simple physical cube.
 We will create the illusion that, on one of its face, there is a cubic
 hole -- as shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-anamorphic-cube"

\end_inset

.
 The cube is physical and the hole will be virtual (drawn in blue).
 The illusion can be generated using the following steps (which are all
 illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-anamorphic-walkthrough"

\end_inset

 and are indicated in parentheses):
\end_layout

\begin_layout Enumerate
Create a virtual camera corresponding to the current user's point of view
 of the scene (
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-anamorphic-top-view"

\end_inset

).
\end_layout

\begin_layout Enumerate
Render the virtual elements (the small cubic hole only) of the scene from
 this virtual camera (
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-anamorphic-hole-only"

\end_inset

).
\end_layout

\begin_layout Enumerate
Reproject the rendered image back onto the virtual replica of the real scene
 -- a simple cube without any hole in it (
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-anamorphic-reprojection"

\end_inset

).
\end_layout

\begin_layout Enumerate
Create a second virtual camera corresponding to the projector's point of
 view using extrinsic and intrinsic parameters retrieved from the projector
 calibration (
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-anamorphic-top-view"

\end_inset

).
\end_layout

\begin_layout Enumerate
Render the scene from this virtual camera (
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-anamorphic-projector"

\end_inset

).
\end_layout

\begin_layout Enumerate
Project the rendered image on the real world environment with the projector
 which, from the point of view of the user, will appear correctly (
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-anamorphic-user-view"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-anamorphic-cube.png
	lyxscale 20
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-anamorphic-cube"

\end_inset

Desired illusion
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-anamorphic-top-view.png
	lyxscale 20
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-anamorphic-top-view"

\end_inset

Top view of virtual scene
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-anamorphic-cube-hole.png
	lyxscale 20
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-anamorphic-hole-only"

\end_inset

Rendered image from user's camera view
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-anamorphic-cube-reprojection.png
	lyxscale 20
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-anamorphic-reprojection"

\end_inset

Reprojection on virtual scene
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-anamorphic-projector.png
	lyxscale 20
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-anamorphic-projector"

\end_inset

View of the projector.
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-anamorphic-user.png
	lyxscale 20
	width 49line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-anamorphic-user-view"

\end_inset

Final view for the user
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-anamorphic-walkthrough"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
Walkthrough on creating projected anamorphic illusions
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
@TODO: Check if discussion about anamorphosis and distance is pertinent.
 I would have liked to say that anamorphosis might work best when the illusion
 is projected on a flat surface.
 If not, it works probably best from a distance since stereo cues can be
 in conflict for what is seen.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Benko2014"

\end_inset

 indicate that the illusion is better for distance evaluation when the virtual
 object is closer to the projection surface.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Benko2012"

\end_inset

 also investigate sar, but uses stereo.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Tools of the trade
\end_layout

\begin_layout Standard
This section give a quick overview of the tools used for the different projects
 highlighted in the following chapters.
 Note that they could easily be swapped for other tools achieving the same
 purpose, but we will justify their choice briefly.
\end_layout

\begin_layout Subsection
Programming: vvvv
\begin_inset CommandInset label
LatexCommand label
name "sub:sar-programming-vvvv"

\end_inset


\end_layout

\begin_layout Standard
vvvv
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://vvvv.org/
\end_layout

\end_inset


\end_layout

\end_inset

 is a general purpose, visual programming toolkit.
 It is the backbone framework of all the projects described further.
 vvvv, while being 
\begin_inset Quotes eld
\end_inset

general purpose
\begin_inset Quotes erd
\end_inset

, has a strong focus on visual installations -- see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-vvvv"

\end_inset

.
 There is only one mode: real-time.
 Everything is done 
\emph on
live
\emph default
 and avoid the dichotomy of 
\begin_inset Quotes eld
\end_inset

code first 
\emph on
then
\emph default
 debug
\begin_inset Quotes erd
\end_inset

 of standard integrated development environments (IDEs).
 Therefore, it is easy to experiment or make fix in real-time which is especiall
y helpful with systems dealing both with digital and real world components.
 Moreover, for interactive system, being able to tweak parameters 
\emph on
while
\emph default
 interacting with the system proves invaluable.
 The framework is built on Microsoft DirectX 9/11 and plugins can be created,
 again in real-time, using the C# language.
 Shaders can also be written in HLSL, in the same way leveraging the immediate
 feedback properties of visual programming.
 Moreover, it natively supports using networks of computers for installations
 that require more processing power.
 From a 
\begin_inset Quotes eld
\end_inset

master
\begin_inset Quotes erd
\end_inset

 computer, it is possible to seamlessly assign certain parts of the program
 to slave machines.
 In a projection setup for example, each projector can be assigned its own
 computer and have the processing be done 
\begin_inset Quotes eld
\end_inset

locally
\begin_inset Quotes erd
\end_inset

.
 It is free to use for non-commercial and educational purposes.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-vvvv.png
	lyxscale 30
	width 100line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-vvvv"

\end_inset

A view of the vvvv visual programming environment.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
vvvv is part of a movement called 
\begin_inset Quotes eld
\end_inset

creative coding
\begin_inset Quotes erd
\end_inset

.
 It put emphasis on code as a mean of expression and of artistic creation.
 Usually, these frameworks try to present high level APIs enabling their
 users to experiment and tinker quickly -- a process essential to creative
 work as is highlighted in Victor's talk 
\begin_inset CommandInset citation
LatexCommand citep
key "Victor2014"

\end_inset

.
 Often, this take the form of very easy access to computer vision algorithms,
 interactive devices such as the Microsoft Kinect and the Leap Motion and
 the easiness of controlling graphics pipelines which, in their basic forms,
 are really difficult to handle to novice programmers and artists.
 Examples of popular creative coding toolkits include Processing
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://processing.org/
\end_layout

\end_inset


\end_layout

\end_inset

, openFrameworks
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://www.openframeworks.cc/
\end_layout

\end_inset


\end_layout

\end_inset

, Pure Data 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://puredata.info/
\end_layout

\end_inset


\end_layout

\end_inset

, Max MSP
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://cycling74.com/products/max/
\end_layout

\end_inset


\end_layout

\end_inset

 and TouchDesigner
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://www.derivative.ca/
\end_layout

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Subsection
Tracking: OptiTrack
\end_layout

\begin_layout Standard
The tracking of the augmented objects were handled with OptiTrack cameras.
 As mentioned before, this tracking solution provide real-time performance
 and precision which is required when working with augmented objects of
 small size -- often smaller than 10 centimeters.
\begin_inset Note Note
status open

\begin_layout Plain Layout
@TODO: Is this really important to mention?
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Calibration
\end_layout

\begin_layout Standard
Calibrating an installation with an OptiTrack camera is slightly different
 than if the tracking would be provided by a standard RGB camera such as
 is the case for fiducial marker based tracking (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:sar-fiducial-markers"

\end_inset

).
 Indeed, OptiTrack cameras are IR cameras, which means that they do not
 
\begin_inset Quotes eld
\end_inset

see
\begin_inset Quotes erd
\end_inset

 visible light.
 Therefore, it is impossible to capture the light projected from a standard
 projector and thus, a projected chessboard required for calibration.
 Some camera models, however, have an IR filter switch, allowing to turn
 off the IR filter.
 However, the resolution of these cameras are relatively low -- 640x480
 pixels in the case of the V120:Trio model -- making it difficult to obtain
 high quality calibrations.
 
\end_layout

\begin_layout Standard
For these reasons, we calibrated the tracking system with the projector
 with a semi-manual method.
 Reflective markers were installed on a standard printed chessboard pattern
 (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sar-chessboard-markers"

\end_inset

).
 That way, using the pose of the rigid body returned by the tracking system,
 we are able to infer the world position of each chessboard corner.
 Then, we manually create corresponding point pairs by selecting points
 
\emph on
using the projector
\emph default
.
 That is, for each given chessboard corner expressed in world position,
 we select the corresponding point in the real world by looking at a projected
 cursor 
\emph on
onto the chessboard
\emph default
.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../img/sar-chessboard-optitrack.jpg
	lyxscale 50
	width 50line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:sar-chessboard-markers"

\end_inset

A chessboard pattern with reflective markers attached to it.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
What is SAR good for?
\end_layout

\begin_layout Standard
Spatial augmented reality in the context of this thesis is a technological
 choice.
 It presents advantages as well as challenges both in terms of technology
 and interaction.
 This section will first discuss the concept of 
\begin_inset Quotes eld
\end_inset

presence
\begin_inset Quotes erd
\end_inset

 which is important to any technology aiming at creating a seamless experience.
 Then, the benefits and drawbacks of SAR will be discussed.
\end_layout

\begin_layout Subsection
Presence
\end_layout

\begin_layout Standard
Presence is defined as the subjective experience of being in an environment,
 even though one is not physically located in said environment 
\begin_inset CommandInset citation
LatexCommand citep
key "Witmer1998"

\end_inset

.
 It is associated to virtual reality which whole purpose is often to immerse
 one or many persons in computer generated artificial worlds and providing
 the experience of 
\begin_inset Quotes eld
\end_inset

being there
\begin_inset Quotes erd
\end_inset

.
 However, one of the reason we are interested in SAR is its potential to
 anchor the digital information 
\emph on
in the real world
\emph default
.
 Therefore, presence, the way it is defined, is not appropriate for our
 context.
 For this reason, Stevens and his colleagues proposed the 
\emph on
object-presence
\emph default
 concept 
\begin_inset CommandInset citation
LatexCommand citep
key "Stevens2002"

\end_inset

.
 Inspired by the definition of presence given by Witmer and Singer 
\begin_inset CommandInset citation
LatexCommand citep
key "Witmer1998"

\end_inset

, they define object-presence as 
\begin_inset Quotes eld
\end_inset

the subjective experience that a particular object exists in a user's environmen
t, even when that object does not
\begin_inset Quotes erd
\end_inset

.
 Bennet and Stevens 
\begin_inset CommandInset citation
LatexCommand citep
key "Bennett2005"

\end_inset

 then evaluated the effect of touching physical objects augmented with front
 projection.
 They found that directly touching -- either with direct touch or using
 a TUI -- an augmented object lowers object presence significantly.
 They hypothesize that it is due to the occlusion of the projection created
 by the hand -- onto which projected content appears -- and the fact that
 the weight and texture of the physical props does not correspond to the
 visual augmented representation.
 We will discuss this issue more in the following section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:sar-drawbacks"

\end_inset

.
\end_layout

\begin_layout Subsection
Benefits
\end_layout

\begin_layout Standard
First and foremost, SAR presents the benefit of being anchored in the real
 world, which is a key component for our line of research.
 By displaying digital elements 
\emph on
onto
\emph default
 the reality directly, it has the potential to leverage all the others cues
 we are used to have in the physical realm.
 Moreover, it is worth mentioning its capabilities to enhance or complement
 physical artifacts which are physically 
\emph on
invaluable
\emph default
 and 
\emph on
unique
\emph default
, such as the ones presented in museums -- e.g.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Basballe2010,Ridel2014"

\end_inset

.
 Using projected light also has the benefit of being being flexible in terms
 of the installation size.
 For example, it is possible to create dynamic rendering over huge buildings
 or very small objects with relatively similar setups
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Of course, projecting over buildings often require more projectors and higher
 lumens output, but the techniques remain the same.
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
When first introducing SAR, Raskar et al.
 made a list of the different advantages of SAR in comparison to standard
 AR 
\begin_inset CommandInset citation
LatexCommand citep
key "Raskar1998a"

\end_inset

.
 Namely, they mention the fact that the user does not need to wear any device
 such as a HMD.
 Larger field of view can also be supported; using multiple projectors allows
 for covering an entire room with projected light.
 Also, since the virtual objects are displayed near their real world location,
 eye accommodation is made easier.
\end_layout

\begin_layout Subsection
Drawbacks
\begin_inset CommandInset label
LatexCommand label
name "sub:sar-drawbacks"

\end_inset


\end_layout

\begin_layout Standard
While SAR comes with many advantages and flexibility, it suffers from different
 shortcomings.
 Already identified by Raskar et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Raskar1998a"

\end_inset

 upon the presentation of the SAR paradigm is the important reliance on
 the display surface properties.
 That is, projecting on highly specular or dark colored diffuse materials
 render the projected content almost invisible.
 Another mentioned problem is the shadow cast by a user manipulating an
 object.
 This problem breaks the illusion in two ways: it casts a shadow on the
 object and it displays the projected content onto the user's hand.
 The first problem can be tackled to an extent by increasing the number
 of projectors used to augment the scene.
 Indeed, with careful placement and blending, it is possible to avoid shadows
 to appear on the surface of the augmented surface 
\begin_inset CommandInset citation
LatexCommand citep
key "Audet2007"

\end_inset

.
 Concerning the second issue, it should be relatively easy to create an
 occlusion mask to avoid projecting on the user occluding an augmented object.
 This could for example be achieved using the Kinect camera point cloud
 combined with its skeleton tracking capabilities.
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
TODO: I would be really surprise if no work tackle this issue, especially
 as 
\begin_inset CommandInset citation
LatexCommand citep
key "Bennett2005"

\end_inset

 mention this issue as a component lowering object presence.
\end_layout

\end_inset

 The overall issue with shadows can alternatively be worked around by using
 rear-projection system such as in 
\begin_inset CommandInset citation
LatexCommand citep
key "Benko2008"

\end_inset

.
 Note, however, that rear-projection systems require a lot more space and
 constraints.
 Small objects would require having a pico projector embedded in them in
 a very stable manner.
 As of today, this is difficult to achieve.
\end_layout

\begin_layout Standard
Using many projectors also make installations more complex to install and
 calibrate in comparison to see-through or video see-through AR.
 Projectors are more complex to calibrate than cameras for the simple reason
 that they are output devices that are not equipped with sensing capabilities
 -- as is explained in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:sar-calibration"

\end_inset

.
 Moreover, multi-projection installations require overlapping sections to
 be carefully blended together to create a uniform augmentation.
 Finally, SAR makes it difficult to display things in 
\begin_inset Quotes eld
\end_inset

mid-air
\begin_inset Quotes erd
\end_inset

 compared to other means of achieving AR.
 One of the way to achieve this is to resort to 3D illusions involving anamorpho
sis (as discussed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:sar-anamorphic-illusions"

\end_inset

).
 Alternatively, it is possible to create a temporary mid-air diffusion medium
 on which to project, such as smoke 
\begin_inset CommandInset citation
LatexCommand citep
key "Seah2014"

\end_inset

 or mist
\begin_inset CommandInset citation
LatexCommand citep
key "MartinezPlasencia2014"

\end_inset

.
\end_layout

\end_body
\end_document
