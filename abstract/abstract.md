## Abstract
<!-- ### Motivation: Why do we care about the problem and the results? -->
Most of our waking hours are now spent staring at a screen. While the advances in touch screens has enabled the use of more expressiveness by using our fingers to interact with digital content, what we see and manipulate on screen is still an emulation of real-world metaphors. The range of capabilities of the human senses are much richer that what screens can currently offer. In order to be sustainable in the future, interaction with the digital world should leverage these human capabilities instead of letting them atrophy. One way to provide richer interaction modalities is to rely on the physical world itself as an host for digital content. Spatial Augmented Reality (SAR) provides a technical mean towards this idea by using projectors to shed digitally controlled light onto real-world objects to augment them and their environment with functionalities and content. This leads the way to smart objects that will have very rich possibilities while still be anchored in the real-world.

<!-- ### Problem statement: What problem are your trying to solve? -->
However, making the real and digital cohabit on a physical medium makes it difficult to interact with the digital content. Direct touch can be a solution most of the time. However, touch is still plagued by the "fat finger" problem and is not appropriate for complex geometries or when precision is required. This thesis is interested in two main questions: How can we interact with projected content when hosted on tangible objects? and how can augmented physical objects be used to increase our awareness of our own human capabilities and senses, i.e. our own body?


### Interaction with Spatial Augmented Reality
The first part of the thesis is focusing on the interaction with augmented objects by the mean of projectors. The work includes an evaluation of a pointing technique (CurSAR) and an interaction metaphor for bridging interaction on traditional computer screens and physical augmented objects.

#### CurSAR
<!-- margin: top right bottom left -->
<img style="float: left; margin: 10px 10px 10px 0px;" width="300" height="150" src="img/cursar.jpg">

CurSAR is a project investigating the use of 2D input devices to point at augmented physical objects. The main goal of the study was to compare the performance of a pointing task

<div style="clear: both"></div>
#### Tangible Viewports: Bridging Desktop Computers and Physical Augmented Objects
<img style="float: right; margin: 10px 0px 10px 10px;" width="300" height="150" src="img/cursar.jpg">
Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.


<!-- ### Approach: How did you go about solving or making progress on the problem? Did you use simulation, analytic models, prototype construction, or analysis of field data for an actual product? -->
We investigated interacting with SAR using traditional input modalities (mouse and graphic tablets) as a basis. Mice are still relevant today for tasks that involve precision and prolonged use. Moreover, they are the default input device with traditional laptops and desktop computers which are the de facto platforms used for creating digital content. We evaluated the performance of using indirect 2D input devices to point at augmented objects without the use of a screen. We found that the performance of using a mouse without the presence of a physical screen reduced the performance (11%) but did not break the interaction metaphor. We also designed an interaction metaphor, Tangible Viewports, an on-screen window enabling physical objects to be used in the context of a desktop computer screen and its native application such as Photoshop. Initial feedback have shown that the metaphor was transparent for the users.

Additionally, we investigated the use of augmented objects for scientific mediation concerning the body. We combined SAR, TUI and physiological computing to create two main systems: Teegi and TOBE. Teegi (Tangible EEG Interface) is a physical puppet that allows novice users to visualize and interact with their live Entrocenphalography (EEG) readings to explore different brain processes. TOBE (Tangible Out of Body Experience) is a platform that enables users to augment and explore in real-time a physical avatar with customized representations that are animated with their physiological readings (ECG, breathing sensor, GSR and EEG).


### Results: What's the answer?


### Conclusions: What are the implications of your answer? Is it going to change the world (unlikely), be a significant "win", be a nice hack, or simply serve as a road sign indicating that this path is a waste of time (of of the previous results are useful)?
